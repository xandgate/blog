---
title: "The Junior Engineer Problem: Who Writes Code When AI Does?"
subtitle: "Thoughtful take on the industry's onboarding challenge"
summary: "If AI can write code better than junior engineers, how do we train the next generation? This is the question keeping me up at night."
image: "/images/gallery/vertical-3.jpg"
publishedAt: "2026-03-07"
tag: "AI Engineering"
---

## The Path Is Over

The traditional junior engineer path — write a lot of code, make mistakes, get reviewed, repeat for three years, become competent — is functionally dead. Not threatened, not disrupted, not "evolving." Over. The specific mechanism by which it produced senior engineers no longer works, because the mechanism depended on implementation being hard.

I want to be precise about this because the comfortable version of this argument — "junior engineers just need to adapt!" — papers over something genuinely serious. The feedback loop that built engineering judgment was: write code, feel it fail, understand why, don't make that mistake again. AI removes the first step. Without the reps, you don't build the reflexes. And without the reflexes, you're not actually an engineer — you're an AI operator, which is a real and valuable job, but it's not the same job, and it doesn't compound the same way.

I was mentoring a junior developer last year — sharp person, motivated, quick learner. She hit a bug she couldn't figure out. I suggested she use Cursor. It fixed the bug in twenty seconds. She moved on. I watched the moment she would have spent an hour debugging — the hour that would have forced her to understand how the event loop actually works — vanish without a trace. She didn't learn anything. She shipped faster. Both of those things are true and one of them is a problem.

## Who Survives This

Here's my actual prediction, stated plainly: **within five years, the entry-level engineering market splits into two tracks that diverge sharply in trajectory.**

Track one: engineers who learned to treat AI as a power tool in a domain they understand. They know why code works, they can debug AI output, they can make architectural calls the AI can't. They become dramatically more productive and their career compounds normally — just faster.

Track two: engineers who learned to generate code they don't understand and ship it. They are productive in the short term and invisible in a layoff. When something breaks in a way AI can't diagnose, they are helpless. When a technical interview asks them to reason about a system without a prompt box, they blank.

The split between these tracks isn't visible yet because we're still in the early phase where headcount is being reduced before it's obvious who's left is competent. When we get to the brittleness phase — when AI-generated systems start failing in production in interesting ways — track two engineers will be exposed.

What separates the tracks isn't intelligence or even effort. It's whether the engineer ever built a genuine mental model of how software works. That model doesn't come from reading documentation. It comes from writing code and watching it fail.

## The Counterintuitive Prescription

Here's the position I expect pushback on: **junior engineers today should deliberately write more code without AI assistance, not less, even though it makes them slower in the short term.**

Not forever. Not for everything. But during the foundational years, when the neural pathways for debugging and systems thinking are forming, using AI to skip implementation is like using a calculator before you understand multiplication. You can do the computation, but you don't understand what you're computing.

The teams I've seen produce strong junior engineers in the AI era have one thing in common: they still require junior devs to implement things from scratch in some defined percentage of their work. They use AI for code review and exploration, not for first-draft generation. It's slower. The output looks worse in the short term. The engineers come out of it with something the other track doesn't have.

This is a hard institutional sell when speed-to-ship is the metric that gets rewarded. I know that. I'm not naive about the economic incentives pulling in the opposite direction. But the companies that let their entire junior cohort skip the foundation are building technical debt of a different kind: a team full of people who can operate systems they don't understand. That's a fragile organization.

## What Good Mentoring Looks Like Now

The mentoring model I've shifted to:

I do code reviews differently. Instead of reviewing the code, I ask the junior developer to explain the code — not what it does, but why it works. If they can't, we go through it together. The inability to explain generated code is not a character flaw; it's diagnostic information about what they need to learn.

I've also started giving deliberately under-specified problems. Not "implement this feature" but "we need to handle user session expiry — figure out the approach and come back with a proposal." AI is useful here. It can generate options. But the engineer has to understand the options well enough to choose, and choosing requires judgment that lives in the person, not the tool.

The goal isn't to produce engineers who can write faster. It's to produce engineers who can think. Those are related skills but they're not the same skill, and one of them is rapidly becoming more valuable while the other approaches commodity status.

---

*If you're a senior engineer mentoring junior devs: what's your actual rubric for assessing whether they're developing real judgment versus becoming fluent prompt engineers? I'd push on that distinction harder than most teams currently do.*
